{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import sys\n",
    "import snowflake.connector as connector\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "st =pd.DataFrame(data=[],columns=['letter','number','dash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>number</th>\n",
       "      <th>dash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter number dash\n",
       "0      1      2    3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.append({'letter':1,'number':2,'dash':3},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method append in module pandas.core.frame:\n",
      "\n",
      "append(other, ignore_index=False, verify_integrity=False, sort=False) -> 'DataFrame' method of pandas.core.frame.DataFrame instance\n",
      "    Append rows of `other` to the end of caller, returning a new object.\n",
      "    \n",
      "    Columns in `other` that are not in the caller are added as new columns.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : DataFrame or Series/dict-like object, or list of these\n",
      "        The data to append.\n",
      "    ignore_index : bool, default False\n",
      "        If True, the resulting axis will be labeled 0, 1, â€¦, n - 1.\n",
      "    verify_integrity : bool, default False\n",
      "        If True, raise ValueError on creating index with duplicates.\n",
      "    sort : bool, default False\n",
      "        Sort columns if the columns of `self` and `other` are not aligned.\n",
      "    \n",
      "        .. versionadded:: 0.23.0\n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "            Changed to not sort by default.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    concat : General function to concatenate DataFrame or Series objects.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    If a list of dict/series is passed and the keys are all contained in\n",
      "    the DataFrame's index, the order of the columns in the resulting\n",
      "    DataFrame will be unchanged.\n",
      "    \n",
      "    Iteratively appending rows to a DataFrame can be more computationally\n",
      "    intensive than a single concatenate. A better solution is to append\n",
      "    those rows to a list and then concatenate the list with the original\n",
      "    DataFrame all at once.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
      "    >>> df\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  3  4\n",
      "    >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
      "    >>> df.append(df2)\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  3  4\n",
      "    0  5  6\n",
      "    1  7  8\n",
      "    \n",
      "    With `ignore_index` set to True:\n",
      "    \n",
      "    >>> df.append(df2, ignore_index=True)\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  3  4\n",
      "    2  5  6\n",
      "    3  7  8\n",
      "    \n",
      "    The following, while not recommended methods for generating DataFrames,\n",
      "    show two ways to generate a DataFrame from multiple data sources.\n",
      "    \n",
      "    Less efficient:\n",
      "    \n",
      "    >>> df = pd.DataFrame(columns=['A'])\n",
      "    >>> for i in range(5):\n",
      "    ...     df = df.append({'A': i}, ignore_index=True)\n",
      "    >>> df\n",
      "       A\n",
      "    0  0\n",
      "    1  1\n",
      "    2  2\n",
      "    3  3\n",
      "    4  4\n",
      "    \n",
      "    More efficient:\n",
      "    \n",
      "    >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
      "    ...           ignore_index=True)\n",
      "       A\n",
      "    0  0\n",
      "    1  1\n",
      "    2  2\n",
      "    3  3\n",
      "    4  4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(st.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "3 columns passed, passed data had 1 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             raise AssertionError(\n\u001b[0m\u001b[0;32m    689\u001b[0m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 3 columns passed, passed data had 1 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2e78c6514c80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mst0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'letter'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'number'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dash'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    507\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# columns if columns is not None else []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 3 columns passed, passed data had 1 columns"
     ]
    }
   ],
   "source": [
    "st0 = pd.DataFrame(data=[[1],[2],[3]],columns = ['letter','number','dash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "append() got an unexpected keyword argument 'column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8cf912bbfb52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'letter'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'number'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dash'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: append() got an unexpected keyword argument 'column'"
     ]
    }
   ],
   "source": [
    "st.append([[1],[3],[4]],column= ['letter','number','dash'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>number</th>\n",
       "      <th>dash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   letter  number  dash\n",
       "0       0       0     0\n",
       "1       1       4     3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.append({'letter':1,'number':4,'dash':3},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amountLetterNumber(data):\n",
    "    #st =pd.DataFrame(data=[0,0,0],columns=['letter','number','dash'])\n",
    "    st = set()\n",
    "    for PN in data:\n",
    "        lr_num = 0\n",
    "        dt_num =0\n",
    "        dash_num =0\n",
    "        if len(PN)>7 and len(PN)<18:\n",
    "            for i in PN:\n",
    "                if i.isdigit():\n",
    "                    dt_num+=1\n",
    "                if i.isalpha():\n",
    "                    lr_num+=1\n",
    "                if i=='-':\n",
    "                    dash_num+=1\n",
    "            if dt_num>1 and lr_numb <3:\n",
    "                b =(lr_num,dt_num,dash_num)\n",
    "                st.add(b)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PN = pd.read_csv('data1/PN.txt',sep='delimiter', header=None,engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_excel('data1/2019_2023PO.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data from snowflake\n",
    "my_query = \"\"\"\n",
    "select \n",
    "a.ebeln as PO,\n",
    "b.ebelp as PO_item,\n",
    "ltrim(b.matnr,'0')as PN,\n",
    "e.description,\n",
    "c.name1 as Vendor_name,\n",
    "c.BRSCH as Industry_key,\n",
    "c.land1,\n",
    "b.netpr as purchased_price,\n",
    "b.menge as PO_qty,\n",
    "a.aedat as po_date,\n",
    "d.eindt as delivery_date,\n",
    "a.waers as original_currency,\n",
    "case when a.waers = 'USD'\n",
    "          then b.netpr\n",
    "          else round(b.netpr*m.exchange_rate,2)\n",
    "end as unit_price_usd,\n",
    "c.zzcatman as Category_manager,\n",
    "f.eknam as Buyer_name,\n",
    "c.zzcatego as category,\n",
    "zzsubcat as SCL,\n",
    "b.werks\n",
    "from (select ebeln,waers,bstyp,ekgrp,lifnr,aedat, concat(waers::text,substring(aedat::text,1,6)) as uni_key from rpl_sap.ekko) as a \n",
    "left join rpl_sap.t024 as f on a.ekgrp = f.ekgrp\n",
    "left join rpl_sap.ekpo as b on a.ebeln = b.ebeln\n",
    "left join rpl_sap.eket as d on b.ebeln = d.ebeln and b.ebelp = d.ebelp\n",
    "left join rpl_sap.lfa1 as c on a.lifnr = c.lifnr\n",
    "left join core.material as e on b.matnr = e.material\n",
    "left join (SELECT from_currency, to_currency, exchange_rate, date_text,concat(from_currency,date_text) as uni_key\n",
    "   FROM ( SELECT c.fcurr AS from_currency,\n",
    "                 c.tcurr AS to_currency, \n",
    "                CASE\n",
    "                    WHEN c.ffact = 0::numeric THEN \n",
    "                    CASE\n",
    "                        WHEN c.ukurs < 0::numeric THEN power(c.ukurs, (-1)::numeric) * (-1)::numeric\n",
    "                        ELSE c.ukurs\n",
    "                    END\n",
    "                    ELSE \n",
    "                    CASE\n",
    "                        WHEN c.ukurs < 0::numeric THEN power(c.ukurs, (-1)::numeric) * (-1)::numeric * c.tfact / c.ffact\n",
    "                        ELSE c.ukurs * c.tfact / c.ffact\n",
    "                    END\n",
    "                END AS exchange_rate,\n",
    "         \"substring\"((99999999 - c.gdatu::bigint)::text, 1, 6) AS date_text,\n",
    "         row_number() OVER(\n",
    "         PARTITION BY \"substring\"(c.gdatu::text, 1, 6), c.fcurr, c.tcurr\n",
    "          ORDER BY c.gdatu) AS ranking\n",
    "           FROM rpl_sap_bi.tcurr as c\n",
    "          WHERE c.kurst::text = 'M'::text AND c.tcurr::text = 'USD'::text) as c\n",
    "  WHERE c.ranking = 1\n",
    "  and date_text >='201201'\n",
    "  order by date_text\n",
    " ) as m on m.uni_key = a.uni_key \n",
    "where b.loekz !='L'\n",
    "and a.bstyp = 'F'\n",
    "and a.aedat >='20220101'\n",
    "and purchased_price >0.01\n",
    "\"\"\"\n",
    "with connector.connect( \n",
    "    user='ethan.zhu@technipfmc.com', # Required. Replace with your email \n",
    "    authenticator=\"externalbrowser\", # Required. \n",
    "    account='technipfmc-data', # Required. \n",
    "    database=\"idsprod\", # Optional \n",
    "    schema=\"public\", # Optional. Replace with the schema you will be working on \n",
    "    role=\"reporting\", # Optional. Replace with the role you will be working with \n",
    "    warehouse=\"reporting_wh\", # Optional. Replace with the warehouse you will be working with \n",
    "    client_store_temporary_credential=True, # Only if installing secure-local-storage to avoid reopening tabs\n",
    "    ) as conn: \n",
    "    cursor = conn.cursor() \n",
    "    cursor.execute(my_query) \n",
    "    df = cursor.fetch_pandas_all() # To return a dataframe\n",
    "df.shape,df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(data):\n",
    "    pn = set(data.index)\n",
    "    b =set((str(2019),str(2020),str(2021),str(2022)))\n",
    "    unique=[]\n",
    "    for i in pn:\n",
    "        m = data.loc[i]\n",
    "        if b.issubset(set((m))):\n",
    "            unique.append(i)\n",
    "    return pd.Series(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('data1/FastenerSpendSummary1.xlsx') as writer:\n",
    "    #repeatPNvsallPN.to_excel(write,sheet_name='repeatPNvsallPN',index=False)\n",
    "    #repeatPNPOVSallPO.to_excel(writer, sheet_name = 'repeatPNPOVSallPO',index =False)\n",
    "    repeatPN.to_excel(writer, sheet_name = 'RepeatPN19-22')#done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
